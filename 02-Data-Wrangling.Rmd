# Data Wrangling

This section deals with the nitty gritty of data analysis. There's no nice plots like the previous chapter. In fact, this data wrangling is the major aspect of data science. 

## Data 

This section on atomic vector, arrays, matrix and list is often considered 
boring and ignored. 

### Vector, Arrays, Matrix

#### Vector and list

All elements of an atomic vector and arrays are the same. A vector is an array with one dimension . List can contain different types of data. A complex example of a structured list is the _json_ format shown below. In base R, _c_ is a function for creating a vector or list. The function _list_ can also be used to create list. It is best to avoid using _c_ when assigning a name to a dataframe or vector [@Wickham2019].

```{r 02-Data-Wrangling-1}
a<-c(1,2,3)
is.vector(a)
class(a) #numeric vector
b<-c("apple","orange","banana")
is.vector(b) #character vector
class(b)
d<-c(1,2,"banana")
is.list(d) #character vector
class(d) #FALSE
e<-list(a,b,c(TRUE,FALSE,FALSE))
is.list(e) #TRUE
```    

#### Matrix and Arrays

In R, an array is a vector organised with attributes such as dimensions. It is of a single data type. It contains a description of the number of dimension. Array can also be accessed by its indexing. 

Later in this chapter, we will illustrate the importance of arrays for manipulating MRI scans. A volumetric mri scan, there are 3 dimenions _[,,]_. The first column is the sagittal sequence, second column is the coronal sequence and the third column is the axial sequence. In the example below, this knowledge of arrays can be used to reverse the ordering of information on MRI scan (flip on it axis between left and right).

```{r 02-Data-Wrangling-1-1}
#vector
vector1<-c(1,2,3)
vector2<-c(4,5,6,7,8,9)

# 2 dimensions
array1<-array(c(vector1,vector2),dim = c(3,3,2))
array1

# 3 dimensions
array2<-array(c(vector1,vector2),dim = c(2,2,3))
array2

#check if array or matrix
is.matrix(array1)
is.array(array1)
```

Arrays can be accessed by indexing its structure.

```{r 02-Data-Wrangling-1-2}
array1[,,1]
```

The second array of array1

```{r 02-Data-Wrangling-1-2-1}
array1[,,2]
```

First row of array1

```{r 02-Data-Wrangling-1-2-2}
array1[1,,]
```

First column of array1

```{r 02-Data-Wrangling-1-2-3}
array1[,1,]
```

A  matrix is a rectangular array of a single data type arranged in rows and columns or a 2 dimensional array. Data type can be number or character. Matrix can be considered a linear combination of vector into a linear map. In R, the function _is.matrix_ returns true only if there is a dimension argument in the data. This definition also means that a dat frame is not a matrix.


```{r 02-Data-Wrangling-1-3}

M1<-matrix(c(1,2,3, 4,5,6),nrow=2, ncol=3, byrow = T,
           dimnames = list(c("row1", "row2"),
                        c("Col1", "Col2", "Col3")))
M1
```
A tensor is multidimensional array. Using the analogy before about a matrix being a linear map, a tensor can be viewed as a multilinear map. More on tensor later.

#### array operations

Array operations are performed element wise.

```{r 02-Data-Wrangling-1-4}
arrayA<-array(c(1,2,3),dim=c(1,3)) #1 row 3 columns
arrayA

arrayB<-array(c(4,5,6),dim=c(1,3))
arrayB

#addition
arrayC=arrayA+arrayB
arrayC

```

Now we illustrate multiplication of arrays

```{r 02-Data-Wrangling-1-4-1}
arrayD=arrayA*arrayB
arrayD
```

Division of arrays

```{r 02-Data-Wrangling-1-4-2}
arrayE<-arrayA/arrayB
arrayE
```

### Operators

##### Relation operators

We test if variable A is same as B by using == operator while we test if A is not equal to B by != operator. A is greater than B by > operator and A is lesser than B by < operator.

#### Logical operators

The _|_ operator signifies elementwise _or_ relationship and _||_ signifies _or_ relationship. The _&_ operator signifies elementwise _and_ relationship and && signifies _and_ relationship.


#### %in%

The _%in%_ operator helps to evaluate if an element belong to a vector. The package _Hmisc_ contains an operator _%nin%_ which is the opposite of _%in%_.

#### %>%

The _%>%_ operator or pipe function, from _magrittr_ package, is used to pass information to the next function.

```{r 02-Data-Wrangling-1-5}
DF<-data.frame(Disability=c("Good","Moderate","Good","Poor"),NIHSS=c(2,10,1,20),Sex=c("M","F","M","M" ))

#create new variable outcome
DF$outcome=ifelse(DF$Disability %in% c("Good","Moderate"), 0,1)
DF

```



### Simple function

a function is written by creating name of function, calling on _function_ (x) 
and brackets to define function.

```{r 02-Data-Wrangling-2}
# function sun
ArithSum<-function (x) {
  sum(x)
}

vector1<-c(1,2,3)
ArithSum(vector1)
```

### for loop

```{r 02-Data-Wrangling-2-1}
vector2<-c(4,5,6)

for (i in vector2){
  print(i)
}
```

Perform math operation using for loop

```{r 02-Data-Wrangling-2-2}

for (i in vector2){
  m= sum(vector2)/length(vector2)
}

m
```

The _next_ command can be used to modify the loop. This simple example removes even number

```{r 02-Data-Wrangling-2-3}
for(i in vector2){
  if(!i %% 2){
    next
  }
  print(i)
}

```

Perform a math operation along the columns.

```{r 02-Data-Wrangling-2-4}

A=c(1,2,3)
B=c(4,5,6)
df=data.frame(A,B)

output_col <- vector("double", ncol(df))  # 1. output
for (i in seq_along(df)) {            # 2. sequence
  output_col[[i]] <- mean(df[[i]])      # 3. body
}
output_col

```

Perform a math operation along the rows.

```{r 02-Data-Wrangling-2-5}
output_row <- vector("double", nrow(df))  # 1. output
for (i in seq_along(df)) {            # 2. sequence
  output_row[[i]] <- mean(df[[i]])      # 3. body
}
output_row


```


### apply, lapply, sapply

#### apply

The _apply_ function works on data in array format.

```{r 02-Data-Wrangling-3}
#sum data across rows ie c(1)
apply(array1,c(1),sum)

#sum data across columns(2)
apply(array1,c(2),sum)

#sum data across rows and columns c(1,2)
apply(array1,c(1,2),sum)
```


#### lapply

The call _lapply_ applies a function to a list. In the section below of medical images the _lapply_ function will be used to creates a list of nifti files and which can be opened painlessly with additional call to _readNIfTI_. Here a more simple example is used.

```{r 02-Data-Wrangling-3-1}
a<-c(1,2,3,4,5,6,7,8)
lapply(a, function(x) x^3)
```

#### sapply

The call _sapply_ applies a function to a vector, matrix or list. It returns the results in the form of a matrix.

```{r 02-Data-Wrangling-3-2, warning=F}
a<-c(1,2,3,4)
sapply(a, function(x) x^2)

```

#### tapply

The _tapply_ function applies a function to a subset of the data.

```{r 02-Data-Wrangling-3-3}

dat.array1<-as.data.frame.array(array1)
dat.array1
```

```{r 02-Data-Wrangling-3-4}
dat.array1$V6<- dat.array1$V6 %% 2
dat.array1$V6
```

```{r 02-Data-Wrangling-3-4-1}
tapply(dat.array1$V1, dat.array1$V6, sum) 
```

The _rapply_ function or recursive apply is applied to a list, contingent on the second argument. In this example, the first function is to multiple elements of the list by 2 contingent on the element being numeric.

```{r 02-Data-Wrangling-3-5}
a<-c(1,2,3.4,D,5, "NA")

rapply(a, function(x) x*2, class="numeric")
```

### Functional

A functional is a function embedded in a function. Later, we will revisit functional to perform analysis on a list of _nifti_ files.

```{r 02-Data-Wrangling-4}

Fou<-lapply(df, function(A) mean(A)/sd(A))

#returns a list
Fou
```

The _unlist_ function returns a matrix.

```{r 02-Data-Wrangling-4-1}

Fou2<-unlist(lapply(df, function(A) mean(A)/sd(A)))

#returns a matrix
Fou2
```

#### Mapply

_Mapply_ applies the function over elements of the data.

```{r 02-Data-Wrangling-4-2}

MeanFou<-lapply(df, mean)

MeanFou[]<-Map('/', df, MeanFou)

```

The equivalent code with _lapply_ is provided below.

```{r 02-Data-Wrangling-4-3}

MeanFou2<-lapply(df, function(M) M/mean(M))

MeanFou2

```

### Iteration

This is an extension of the discussion on functional programming. Here we will be using _purrr_ library and _map_ function to apply function to multiple input. First, we use _split_ function to partition data.

```{r 02-Data-Wrangling-4-4}
library(purrr)
library(dplyr)

ss<-read.csv("./Data-Use/ss150718.csv") 
ss%>% 
  select(duplicate, PubYear, TP,FP,FN,TN) |> 
  split(ss$duplicate) %>% head()
```

Following on from the splitting of the data, we perform the regression on the split data with _map_.

```{r 02-Data-Wrangling-4-5}

ss %>% select(duplicate, PubYear, TP, FP, FN, TN) %>% mutate(Sensitivity=TP/(TP+FN)) |> 
  split(ss$duplicate) |>
  map(\(df) lm(Sensitivity ~ PubYear, data = df))|> 
  map(summary) 


```

We can extend this function to each element of a vector to get the output for the linear regression on the partition data.

```{r 02-Data-Wrangling-4-5-1}
ss %>% select(duplicate, PubYear, TP, FP, FN, TN) %>% mutate(Sensitivity=TP/(TP+FN)) |> 
  split(ss$duplicate) |>
  map(\(df) lm(Sensitivity ~ PubYear, data = df))|> 
  map(summary) %>%
  map_dbl("r.squared")

```

#### map characters

The _map_ function can be applied to characters. This can be illustrated using the spot sign data

```{r 02-Data-Wrangling-4-5-2}

map2_chr(ss$Authors, ss$PubYear, ~paste(.x, .y, sep=": ")) %>% head()
```

The characters can be mapped to upper case.

```{r 02-Data-Wrangling-4-5-3}
library(stringr)
map2_chr(ss$Authors, ss$PubYear, ~paste(.x, .y, sep=" - ")) %>% 
  map_chr(~str_to_upper(.)) %>%
  head()
```

The _purrr_ library has function to _pluck_ items from the list or data frame.

```{r 02-Data-Wrangling-4-5-4}
map2_chr(ss$Authors, ss$PubYear, ~paste(.x, .y, sep=" - ")) %>% 
  pluck(1) 
```

## Data storage

Often one assumes that opening Rstudio is sufficient to locate the file and run the analysis. One way of doing this at the console is to click on _Session_ tab, then _Set Working Directory_ to location of file. Another way of doing this seemlessly is to use the library _here_. It is easy to find the files in your directory using the _list.files()_ call. 

```{r 02-Data-Wrangling-4-6, echo=F, eval=F}

list.files()
```

To list only some files use pattern matching.

```{r 02-Data-Wrangling-4-6-1, echo=F, eval=F}

list.files(pattern = "*.Rmd")
```


We can increase the complexity of pattern matching.

```{r 02-Data-Wrangling-4-6-2}
#list files matching pattern
list.files(pattern=".Rmd|*.stan")
```

### Data frame

Data frame is a convenient way of formatting data in table format. It is worth checking the structure of data. Some libraries prefer to work with data in data frame while others prefer matrix or array structure.

```{r 02-Data-Wrangling-5}
a<-c(1,2,3)
b<-c("apple","orange","banana")
e<-data.frame(a,b)
rownames(e)
```

### Excel data

Excel data are stored as csv, xls and xlsx.  Csv files can be open in base R 
using _read.csv_ function or using _readr_ library and _read_csv function_. I would urge you to get used to manipulating data in R as the codes serve as a way to keep track with the change in data. The original xcel data should not be touched outside of R. A problem with excel data is that its autocorrect function change provenance of genomic data eg SEPT1, MARCH1. SEPT1 is now relabeled as SEPTIN1.

```{r 02-Data-Wrangling-5-1, eval=F}
A<-read.csv("File.csv")

B<-readr::read_csv ("File.csv")
```

The _readxl_ library can be used to open files ending in xls and xlsx.

```{r 02-Data-Wrangling-5-2, eval=F}

C<-readxl::read_xlsx("File.xlsx",skip=1) #skip first row 

D<-readxl::read_xlsx("File.xlsx",sheet=2) #read data from sheet 2
```

#### Date and time

Date and time can be handle in base R. The library _lubridate_ is useful for parsing date data. It is possible to get an overview of the functions of the library by typing _help(package=lubridate)_. Errors with parsing can occur if there are characters in the column containing date data. 

```{r 02-Data-Wrangling-6}
library(dplyr)

dfdate<-data.frame("DateofEvent"=c("12/03/2005","12/04/2006",NA),
                   "Result"=c(4,5,6))
class(dfdate$DateofEvent)
dfdate$DateofEvent
```

The date column appears to be listed as character because of NA. This is easily fixed by filtering NA.

```{r 02-Data-Wrangling-6-1}

dfdate$`Date.of.Event`<-dfdate$DateofEvent
#remove NA using filter
dfdate %>% filter(!is.na(DateofEvent))

#re assigning date data type
dfdate$DateofEvent2<-as.POSIXct(dfdate$DateofEvent)
dfdate$DateofEvent3<-as.POSIXct(dfdate$`Date.of.Event`)
class(dfdate$DateofEvent2)
dfdate$DateofEvent2


```

Problem can occur when date and time are located in separate columns. The first issue is that time data is assigned a default date 1899-12-30. This error occurs as the base date in MS Office is 1899-12-30. This issue can be compounded when there are 2 time data eg a patient has stroke onset at 22:00 and is scanned at 02:00. The data become 1899-12-31 22:00 and 1899-12-31 02:00. In this case it implies that scanning occurs before stroke onset. This could have been solved at the data collection stage by having 2 separate date colums. There are several solutions inclusing _ifelse_ but care must be taken with this argument. Note 
that _ifelse_ argument convert date time data to numeric class. This can be resolved by embedding _ifelse_ statement within _as.Date_ argument. This argument requires _origin_ argument. The logic argument may fail when the default date differ eg 1904-02-08 02:00. In this case 1904-02-08 02:00 is greater than 1899-12-31 22:00.

```{r 02-Data-Wrangling-6-2}
library(lubridate)
library(tidyverse)

df<-data.frame("Onset_date"=c("2014-03-06","2013-06-09"), "Onset_Time"=c("1899-12-31 08:03:00","1899-12-31 22:00:00"), "Scan_Time"=c("1904-02-08 10:00:00","1899-12-31 02:00:00")) %>% 
  mutate(
  #use update argument to reassign year, month and day
  Scantime=update(ymd_hms(Scan_Time), year=year(ymd(Onset_date)), month=month(ymd(Onset_date)), mday=day(ymd(Onset_date))),
 
  Onsettime=update(ymd_hms(Onset_Time), year=year(ymd(Onset_date)), month=month(ymd(Onset_date)), mday=day(ymd(Onset_date))),
  
  Scan_date=ifelse(Onsettime>Scantime,1,0),
  Scantime=Scantime+Scan_date*hms("24:00:00"),
  
 DiffHour=Scantime-Onsettime #minutes
)

df %>% select(-Scan_date) %>% gt::gt()



```


One way of storing data in R format is to save the file as .Rda. This format 
will ensure that no one can accidentally rewrite or delete a number. For very large data, it's quicker to save as .Rda file than as csv file.

### Foreign data

The foreign library is traditionally use to handle data from _SPSS_ (.sav), _Stata_ (.dta) and _SAS_ (.sas). One should look at the ending in the file to determine the necessary library. 

```{r 02-Data-Wrangling-7, eval=FALSE}
library(foreign)
#write and read Stata
write.dta(dfdate,file="./Data-Use/dfdate_temp.dta")
a<-read.dta("./Data-Use/dfdate_temp.dta")
a
```

The _foreign_ library can handle older _SAS_ files but not the current version. The current version of _SAS_ file requires _sas7bdat_. The clue is the file ends in .sas7bdat.

### json format

Json is short for JavaScript object Notification. These files have a 
hierarchical structured format.  The json file is in text format amd can also be examined using _Notepad_. These files can be read using the _RJSONIO_ or _rjson_ 
libraries in R. Geojson is a json format with geographical data.

```{r 02-Data-Wrangling-8}
library(RJSONIO)
j<-fromJSON("./Data-Use/0411.geojson") #Christionso Island
j<-lapply(j, function(x) {
  x[sapply(x,is.null)]<-NA
  unlist(x)
})
k<-as.data.frame(do.call("cbind",j)) #list to data frame
head(k)
```

The geojson file can be converted to sf using _geojson_sf_ function from _geojsonsf_ library.

```{r 02-Data-Wrangling-8-1}

library(geojsonsf)

#Christianso Island
geojson_sf("./Data-Use/0411.geojson")  %>% mapview::mapview()
```


## Tidy data

Attention to collection of data is important as it shows the way for performing analysis. In general each row represents on variable and each column represents 
an attribute of that variables. Sometimes there is a temptation to embed 2 types of attributes into a column. 

```{r 02-Data-Wrangling-9}
df2<-data.frame(Sex=c("Male","Female"), Test=c("positive 5 negative 5",
                        " negative 0 negative 10"))
df2
```

The above example should be entered this way. This change allows one to group variables by Test status: 'positive' or 'negative'. One can easily perform a 
t-test here (not recommend in this case as the data contains only 2 rows).

```{r 02-Data-Wrangling-9-1}
df2<-data.frame(Sex=c("Male","Female"), `Test Positive` =c(5,0), `Test Negative`=c(5, 10))
df2
```

The below example is illustrate how to collapse columns when using base R. 

```{r 02-Data-Wrangling-10}

dfa<-data.frame(City=c("Melbourne","Sydney","Adelaide"),
                State=c("Victoria","NSW","South Australia"))
#collapsing City and State columns and generate new column address
dfa$addresses<-paste0(dfa$City,",", dfa$State) #separate by comma
dfa$addresses2<-paste0(dfa$City,",", dfa$State,", Australia")
dfa
```

This example is same as above but uses verbs from _tidyr_. This is useful for collapsing address for geocoding. 

```{r 02-Data-Wrangling-10-1}
library(tidyr)
dfa1<-dfa %>% unite ("new_address",City:State,sep = ",")
dfa1
```

Using the data above, let's split the column address

```{r 02-Data-Wrangling-11}
library(tidyr)
dfa2<-dfa1 %>% separate(addresses, c("City2", "State2"))
dfa2
```

### Factors

There are several types of factors in R: ordered and not ordered. It is 
important to pay attention to how factors are coded. Sometimes, male is represented as 1 and female as 0. Sometimes, female is represented as 2 as integer encoding. Integer encoding assumes a rank ordering. This discussion may seems trivial but several papers have been retracted in high impact factor journal Jama because of miscoding of the trial assignment 1 and 2 rather than the assignment of 0 and 1. This error led to reversing the results with logistic regression when 2 is exchanged for 0 [@pmid31593277]. This error led to report that an outpatient management program for chronic obstructive pulmonary disease resulted in fewer admissions. Below is an example which can occur when data is transformed into factor and back to number. Note that the coding goes from 0 and 1 to 2 and 1. It has been suggested that the move away from coding data as 1 and 0 was historical and due to the fear that coding with punch card would treat 0 as a missing number and hence the move to coding binary variable as 1 and 2.

In certain analyses, the libraries prefer to use the dependent  or outcome variable as binary coding in numeric format such as 1 and 0 eg logistic regression and random forest. The library _e1071_ for performing support vector machine prefers the outcome variable as factor. 

```{r 02-Data-Wrangling-12}
library(Stat2Data)
data("Leukemia") #treatment of leukemia

Leukemia %>% dplyr::glimpse()
```

The variable Resp is now a factor with levels 0 and 1

```{r 02-Data-Wrangling-12-1-1}
Leukemia$Resp
Leukemia$Response.factor<-as.factor(Leukemia$Resp)
head(Leukemia$Response.factor)
```

Note in the conversion back to numeric 'dummy' values, the data takes the form 1 and 2. This has changed the dummy values of 0 and 1. It is important to examine the data before running analysis.

```{r 02-Data-Wrangling-12-2}
Leukemia$Response.numeric<-as.numeric(Leukemia$Response.factor)
Leukemia$Response.numeric
```

For variables which are characters but considered as factors, it is necessary to convert to class character before converting to dummy values.

```{r 02-Data-Wrangling-12-3}
data("BreastCancer", package="mlbench")
BreastCancer %>% glimpse()
```

The steps for conversion are illustrated below. Conversion of multiple columns 
of factors and ordered factors can be done in one step using _lapply_ function. This will be described much further below. 

```{r 02-Data-Wrangling-12-3-1}
BreastCancer$Class<-as.character(BreastCancer$Class)
BreastCancer$Class[BreastCancer$Class=="benign"]<-0
BreastCancer$Class[BreastCancer$Class=="malignant"]<-1
BreastCancer$Class<-as.numeric(BreastCancer$Class)
head(BreastCancer$Class)

```


This illustration describes conversion of a continuous variable into orderly factors.

```{r 02-Data-Wrangling-12-4}
library(Stat2Data)
data("Leukemia") #treatment of leukemia
#partition Age into 8 ordered factors
Leukemia$AgeCat<-ggplot2::cut_interval(Leukemia$Age, n=8, ordered_result=TRUE)
class(Leukemia$AgeCat)
```


### Multiple files

Merging of files can be done using _dplyr_ to perform _inner_join_, 
_outer_join_, _left_join_ and _right_join_. Note that this can also be done in base R or using syntax of _data.table_. These files can be joined using  _%>%_ operator.

```{r 02-Data-Wrangling-12-5}
DF1<-data.frame(ID=c(1,2,3),Age=c(20,30,40))
DF2<-data.frame(ID=c(1,2,3),Sex=c(1,0,0))
DF3<-data.frame(ID=c(1,2,3), Diabetes=c(1,1,0))

DF <-DF1 %>% left_join(DF2, by="ID") %>% left_join(DF3, by="ID")


```

### Tidy evaluation

Data in a dataframe can be summarised with the help of _group_by_ function in _dplyr_. The _summarise_ function returns 1 row of data per group. The number of observations in each group can be counted using _n()_ function.

```{r 02-Data-Wrangling-13}
# spot sign dataset
ss<-read.csv("./Data-Use/ss150718.csv")

ss %>% group_by(Country) %>% summarise (Number=n())



```

We can add more arguments to the _group_by_ function

```{r 02-Data-Wrangling-13-1}

ss %>% group_by(Country, Study.type) %>% summarise (Number=n())

```
We can also apply a function across multiple columns with _across_. Here we use _reframe_ argument to unlock restriction impose by _group_by_. Here we use _tibble_ function to return several output columns.

```{r 02-Data-Wrangling-13-2}
DR<- function (w,x,y,z){
  tibble(
   Sensitivity=round(w/(w+y),2),
   Specificity=round(z/(z+x),2))
}

ss %>% group_by(Country, Study.type) %>% 
  #the output is limted to 6 rows by head argument
  reframe (across(TP:TN), DR(TP,FP,FN,TN)) %>% head() 
```


### Pivot wide and long

A variety of different expressions are used to describe data format such as wide and long formats. In some case the distinction between such formats is not 
clear. The verbs for performing these operations are _pivot_wide_, _pivot_long_. Again _data.table_ uses different verbs such as _cast_ and _melt_. In general, most regression analyses are performed with data in wide format. In this case 
each row represents a unique ID.  Longitudinal analyses are performed with data 
in long format. In this format, there are several rows with the same ID. In the next Chapter on Statistics, an example of data generated in wide format and coverted to long format using _plyr_. Here we will demonstrate the use of 
_tidyr_ to pivot loner or wider. 

The best way to think about how data should be presented is that data is 
analyzed according to columns not rows. The data below is extracted from CDC 
COVID website. Details are given below under Web scraping on how this task was performed.

```{r 02-Data-Wrangling-14, warning=F}
library(dplyr)
library(tidyr)
library(stringr)
usa<-read.csv("./Data-Use/Covid_bystate_Table130420.csv")
# for demonstration we will select 3 columns of interest
usa_long <-usa %>% 
  select(Jurisdiction,NumberCases31.03.20,NumberCases07.04.20) %>% pivot_longer(-Jurisdiction,names_to = "Date",values_to = "Number.Cases")  
usa_long$Date <- str_replace(usa_long$Date,"NumberCases","")

#data in wide format
head(usa %>%select(Jurisdiction,NumberCases31.03.20,NumberCases07.04.20),6) 

#data in long format
head(usa_long,6) 
```

## Regular Expressions

Here is a short tutorial on regular expression. We will begin using base R. This section is based on experience trying to clean a data frame containing many 
words used to describe one disease or one drug.

### base R

```{r 02-Data-Wrangling-15}
#create example dataframe
df<-data.frame(
  drug=c("valium 1mg","verapamil sr","betaloc zoc","tramadol","valium (diazepam)"),
  infection=c("pneumonia","aspiration pneumonia","tracheobronchitis","respiratory tract infection","respiratory.tract.infection"))
df
```

Now that we have a data frame, we can use pattern matching to replace part of phrase. This step can be done simply using _gsub_ command. First create a list 
so that the computer searches the phrases in the list.

```{r 02-Data-Wrangling-15-1}
#create list to remove phrase
redun=c("1mg", "zoc", "sr")
pat=paste0("\\b(",paste0(redun,collapse = "|"),")\\b")
df$drug1<-gsub(pat,"",df$drug)
df$drug1
#create list to remove phrase
redunc1=c("respiratory tract infection", "tracheobronchitis", "aspiration")
pat=paste0("\\b(",paste0(redunc1,collapse = "|"),")\\b")
df$infection1<-gsub(pat,"",df$infection)
df$infection1
```

This section deals with meta-characterers. Examples of meta-characters include 
$ . + * ? ^ () {} []. These meta-characters requires the double back slashes \\.

```{r 02-Data-Wrangling-15-2}
#create list to remove phrase
redun=c("1mg", "zoc", "sr")
pat=paste0("\\b(",paste0(redun, collapse = "|"),")\\b")   
df$drug2<-gsub(pat,"",df$drug)

#[a-z] indicates any letter
#[a-z]+ indicates any letter and those that follow the intial letter
df$drug2<-gsub("\\(|[a-z]+\\)","",df$drug2)
df$drug2
```

Back to our data frame df, we want to remove or change the different words accounting for pneumonia.

```{r 02-Data-Wrangling-15-3}
redunc=c("\\.")
redunc1=c("respiratory tract infection", "tracheobronchitis", "aspiration")
pat=paste0("\\b(",paste0(redunc,collapse = "|"),")\\b")
df$infection2<-gsub(pat," ",df$infection)
pat=paste0("\\b(",paste0(redunc1,collapse = "|"),")\\b")
df$infection2<-gsub(pat," ",df$infection2)
df$infection2
```

### stringr

The following examples are taken from excel after conversion from pdf. In the process of conversion errors were introduced in the conversion from pdf to excel. A full list of the options available can be found at https://stringr.tidyverse.org/articles/regular-expressions.html

```{r 02-Data-Wrangling-16}
library(stringr)
#error introduced by double space 
a<-c("8396 (7890 to 8920)","6 301 113(6 085 757 to 6 517 308)",
     "4 841 208 (4 533 619 to 5 141 654)",
     "1 407 701 (127 445 922 to 138 273 863)",
     "4 841 208\n(4 533 619 to\n5 141 654)")

b<-str_replace (a, "\\(c.*\\)","")

#this is a complex example to clean and requires several steps. Note that the original data in the list a is now assigned to b. 
b<-str_replace(a,"\n","") %>% 
  #remove (
  str_replace("\\(.*","") %>%
  str_replace("\n.*","") %>%
  #remove )
  str_replace("\\)","") %>%
  #remove empty space
  str_replace("\\s","") %>%
  str_replace("\\s","")%>% as.numeric()
b
```

Another example. This time the 2 numbers in the column are separated by a slash sign. Supposed you want to keep the denominator. The first remove the number before the slash sign. The _*_ metacharacter denotes the action occurs at the 
end.

```{r 02-Data-Wrangling-17}
df.d<-data.frame(seizure.rate=c("59/90", "90/100", "3/23"))
df.d$seizure.number<-str_replace(df.d$seizure.rate,"[0-9]*","") 
df.d$seizure.number
```

Now combine with the next step to remove the slash sign. 

```{r 02-Data-Wrangling-17-1}
#We used [0-9] to denote any number from 0 to 9. For text, one can use [A-Z].
df.d$seizure.number<-str_replace(df.d$seizure.rate,"^[0-9]*","")%>%
  str_replace("/","\\")
df.d$seizure.number
```

Removing the denominator requires a different approach. First remove the last number then the slash sign. 

```{r 02-Data-Wrangling-17-2}
df.d$case<-str_replace(df.d$seizure.rate,"/[0-9]*"," ")
df.d$case
```

The example below has several words mixed in numeric vector columns. The words 
are a mixture of upper and lower cases. Note that "NA" is treated as a word character while _NA_ is treated as Not Available by R. This recognition is important as removing them requires different actions. Character "NA" can be removed by _str_replace_ while _NA_ requires _is.na_ operator. 

```{r 02-Data-Wrangling-18}
A<-c(1,2,3,"NA",4,"no COW now")
B<-c(1,2,NA,4,"NA","check")
C<-c(1,"not now",2,3, NA ,5)

D<-data.frame(A,B,C) 

#str_replace on one column
D$A1<-str_replace(D$A,"[A-Z]+","") %>% str_replace("[a-z]+","")

#change to lower case
D$A2<-str_to_lower(D$A) %>% str_replace("[a-z]+","")

#remove space before replacement
D$A3<-str_to_lower(D$A) %>% str_replace("\\s+","") %>% str_replace("[a-z]+","")

#note that this action does not remove the third word
D$A4<-str_to_lower(D$A) %>% str_replace("\\s","") %>% str_replace("[a-z]+","")

#repeat removal of empty space
D$A5<-str_to_lower(D$A) %>% str_replace("\\s","") %>% 
  str_replace("\\s","") %>%  str_replace("[a-z]+","")

#apply str_replace_all rather than repeat
D$A6<-str_to_lower(D$A) %>% str_replace_all("\\s","") %>% 
    str_replace("[a-z]+","")

#now combine into vector. Note the use of c to combine the vector and replace 
#the comma with equal sign
D$A7<-str_to_lower(D$A) %>%
 str_replace_all(c("\\s"="","[a-z]+"=""))

D
```

The lessons from above can be combine in when creating data frame. The 
_mutate_if_ function enable multiple columns to be changed. One problem to 
handle adding multiple columns which contain _NA_ is the use of _rowSums_ and _dplyr::select_. These examples are illustrated below.

```{r 02-Data-Wrangling-19}
#use the mutate function 

E<-data.frame(A,B,C) %>%
  mutate (A=str_to_lower(A) %>% str_replace_all(c("\\s"="","[a-z]+"="")),
          B=str_to_lower(B) %>%str_replace_all(c("\\s"="","[a-z]+"="")),
          C=str_to_lower(C) %>%str_replace_all(c("\\s"="","[a-z]+"="")))%>%
  
  #change character columns to numeric
  mutate_if(is.character, as.numeric)%>%
  
  #add across columns and avoid NA
  mutate(ABC=rowSums(dplyr::select(.,A:C),na.rm = T))
```

Another example of NA creating issues with _sum_ in mutate is provided below. Here, the function _rowwise_ from _dplyr_ can be used to emphasise the operation across rows. 

```{r 02-Data-Wrangling-19-1, warning=F}

df<-data.frame(Mon_SBP=c(160,NA,180),Tues_SBP=c(0,0,150),
               Wed_SBP=c(NA,130,125)) %>%
  #error from NA
  rowwise %>%
  mutate(SBP=ifelse(sum(Mon_SBP>140 & Tues_SBP>120, 
                        Tues_SBP>100 & Wed_SBP>120, 
                        Mon_SBP>100 & Wed_SBP>115, na.rm=T)>1.5,1,0))


df
          


```

Sometimes, you may only want to keep the number and ignore the words in the column. This can be done using the _str_extract_ function.

```{r 02-Data-Wrangling-20, warning=F}

df.e<-data.frame(disability=c("1 - No significant disability despite symptoms; able to carry out all usual duties and activities","5 - Severe disability, bedridden, incontinent and requiring constant nursing care and attention","
1 - No significant disability despite symptoms; able to carry out all usual 
duties and activities"))
df.e$disability2<-str_extract(df.e$disability,"\\w") #extract number
```

## PDF to xcel

Sometimes data from public government sites come in PDF form instead of excel. Conversion from pdf to excel or text can be difficult especially with special character eg Danish. There are several libraries for doing this: _pdftables_ (require API key) and _pdftools_. The example below uses _pdftools_. 
available at https://docs.ropensci.org/pdftools/. The document is the 2018 
Danish Stroke Registry report. The _tabulizer_ package is excellent for 
converting table data. However, _tabulizer_ package depends on _rJava_ and requires deft handling. The _PDE_ libray has user interface for performing data extraction from pdf.

```{r 02-Data-Wrangling-21}
library(pdftools)

#Danish stroke registry
txt<-pdf_text("./Data-Use/4669_dap_aarsrapport-2018_24062019final.pdf")
cat(txt[17]) #browse data page 13+4 filler pages

screenshot13<-
  pdf_render_page("./Data-Use/4669_dap_aarsrapport-2018_24062019final.pdf", 
                  page =17)
png::writePNG(screenshot13, "./Data-Use/Danish-Stroke-page13.png")

knitr::include_graphics("./Data-Use/Danish-Stroke-page13.png")
```



### Scanned text or picture

Importing data from scanned text will require use of Optical Character 
Recognition (OCR). The _tesseract_ library provides an R interface for OCR. In 
the example below, a picture is taken from same CDC website containing mortality data (https://www.cdc.gov/coronavirus/2019-ncov/covid-data/covidview/04102020/
nchs-data.html). The screenshot of this website was then cleaned in _paint_. 
The data is available in the Data-Use folder.

```{r 02-Data-Wrangling-22}
library(tesseract)
eng <- tesseract("eng") #english
text <- tesseract::ocr("./Data-Use/Covid_PNG100420.png", engine = eng)
cat(text)
```

## Web scraping

The readers may ask why web scraping for healthcare. A pertinent example related to COVID-19 data is provided below. The library _rvest_ is helpful at scraping data from an internet page. The _rvest_ library assumes that web contents have 
xml document-tree representation. The different options available for web 
scraping with _rvest_ are available at the website https://rvest.tidyverse.org/reference/. The user can use CSS selectors to scrape content. The library _Rselenium_ is also useful for web scraping. For dynamic 
web page, the library _CasperJS_ library does a better job especially if the 
data contain embedded java script. 

The library _cdccovidview_ provides access to the CDC website on COVID-19. In 
the example below, we will try to this manually. Data from CDC website on 
COVID-19 is downloaded, cleaned and saved in csv format. It is important to pay attention to the data. The first row contains header and is removed. There are several columns with commas. These commas can be removed using the exercises above. Further the data is updated on weekly basis. As such the data needs to be converted into a date time format using _lubridate_. 

```{r 02-Data-Wrangling-23}
library(rvest)
library(tidyverse)
#assign handle to web page accessed 12/4/20
#cdc<-read_html("https://www.cdc.gov/coronavirus/2019-ncov/covid-data/
#               covidview/04102020/nchs-data.html")
# scrape all div tags
#html_tag <- cdc %>% html_nodes("div")
# scrape header h1 tags
#html_list<-html_tag %>% html_nodes("h1") %>% html_text()
#there is only one table on this web page
#Table1<- cdc %>% html_node("table") %>% html_table(fill = TRUE)
#Table1 has a header row
#Table1<-Table1[-1,]
#The data in the Total Deaths column has a comma 
#Table1$Total.Deaths<-as.numeric(gsub(",","",Table1$`Total Deaths`))
#now combine the year and week column to Date
#Table1$Date<-lubridate::parse_date_time(paste(Table1$Year, Table1$Week, 'Mon', sep="/"),'Y/W/a')
#there are still commas remaining in some columns. This is a useful exercise for the reader. A solution is provided in the next example.  
#write.csv(Table1,file="./Data-Use/Covid_Table100420.csv")
```

The next example is from the CDC COVID-19 website. It poses a different 
challenges as there are several columns with the same names. In this case we 
will rename the column by index. There are several columns containing commas. Rather than removing column by column we will write a function with lapply to do it over the table. the apply function returns a matrix whereas lapply returns a dataframe. There is one column containing percentage enclosed in a bracket. This can be removed using the example above on metacharacter ie using doule back slash in front of bracket and again at close of bracket.

```{r 02-Data-Wrangling-24}
library(rvest)
library(tidyverse)
cdc<-
read_html("https://www.cdc.gov/mmwr/volumes/69/wr/mm6915e4.htm?s_cid=mm6915e4_w")

# scrape all div tags
html_tag <- cdc %>% html_nodes("div")
# scrape header h1 tags
html_list<-html_tag %>% html_nodes("h1") %>% html_text()
#there is only one table on this web page
Table2<- cdc %>% html_node("table") %>% html_table(fill = TRUE)
#first row is header
names(Table2) <- as.matrix(Table2[1, ])
Table2<-Table2[-c(1:2,55),]#rows 1 and 2 are redundant
#rename the columns by index 
names(Table2)[2] <-"NumberCases31.03.20"
names(Table2)[3]<-"CumulativeIncidence31.03.20"
names(Table2)[4]<-"NumberCases07.04.20"
names(Table2)[5]<-"NumberDeath07.04.20"
names(Table2)[6]<-"CumulativeIncidence07.04.20"
#rather than removing column by column we will write a function with lapply to remove commas over the table. the apply function returns a matrix whereas lapply returns a dataframe.
Table2<-as.data.frame(lapply(Table2, function(y) gsub(",", "", y))) 
Table2<-as.data.frame(lapply(Table2, function(x)
  gsub("\\(|[0-9]+\\)","",x)))
#write.csv(Table2,file="./Data-Use/Covid_bystate_Table130420.csv")
```

## Medical Images

### DICOM and nifti format

R can handle a variety of different data format. Medical images are stored as _DICOM_ files for handling and converted to _nifti_ files for analysis. The workhorses are the _oro.dicom_ and _oro.nifti_ libraries. Nifti is an S4 class object with multiple slots for data type. These slots can be accessed by typing the @ after the handle of the file.  The values in an image can be evaluated using _range_ function. Alternately, use _cal_max_ and _cal_min_ to perform the same task. It appears that in the conversion from minc file to nifti file, a scaling factor has been applied and transformed the values.

```{r 02-Data-Wrangling-25, warning=F}
library(oro.nifti)
mca<-readNIfTI("./Data-Use/mca_notpa.nii.gz", reorient = FALSE) 

range(mca)
```

The slots also contain information on whether the data has been scaled. This can be checked by accessing the _scl_slope_ and _scl_inter_ slots. These data on slope and intercept provide a mean of returning an image to its correct value.

```{r 02-Data-Wrangling-25-1, warning=F}
mca@scl_slope
```

To find available slots

```{r 02-Data-Wrangling-25-2, warning=F}
#find available of slots
slotNames(mca)

```

In this example below we will simulated an image of dimensions 5 by 5 by 5. see [simulation using mand library][PCA with MRI].

```{r 02-Data-Wrangling-25-3, warning=F}
library(oro.nifti)
set.seed(1234)
dims = rep(5, 3)
SimArr = array(rnorm(5*5*5), dim = dims)
SimIm = oro.nifti::nifti(SimArr)
print(SimIm)
```

View the simulated image.

```{r 02-Data-Wrangling-25-4, warning=F}
neurobase::ortho2(SimIm)
```

This section provides a brief introduction to viewing nifti files. Data are stored as rows, columns and slices. To view sagital image then assign a number to the row data.

```{r 02-Data-Wrangling-26}

#plot mca #sagittal
image(mca[50,,]) 
```

To see coronal image, assign a number to the column data.

```{r 02-Data-Wrangling-26-1}
#plot mca #coronal
image(mca[,70,]) 
```

To see axial image, assign a number to the slice data.

```{r 02-Data-Wrangling-26-2}
#plot mca #axial in third column
image(mca[,,35]) 
```

### Manipulating array of medical images

These arrays of medical images should be treated no differently from any other arrays. The imaging data are stored as arrays within the _.Data_ slot in nifti.

Data can be subset using the square bracket. The image is referred to x (right to left), y (front to back), z (superior to inferior).

```{r 02-Data-Wrangling-27, warning=F}
library(oro.nifti)
#extract data as array using @ function
img<-readNIfTI("./Data-Use/mca_notpa.nii.gz", reorient = FALSE) 
k<-img@.Data

#change x orientation to right to left 91*109*91
k1<-k[91:1,,] 
#access slice 35 to verify that the image orientation has been switched.
image(k1[,,35])
```

With the image now flipped to the other side, we can create an image by returning the array into a data slot.

```{r 02-Data-Wrangling-27-1, warning=F}
img2<-img
img2@.Data <- k1
img2
```

Arrays can be manipulated to split an image into 2 separate images. Below is a function to split B0 and B1000 images from diffusion series.

```{r 02-Data-Wrangling-27-2, warning=F}

#split dwi file into b0 and b1000
#assume that b1000 is the second volume
#dwi<-readNIfTI("....nii.gz",reorient = F)

DWIsplit<-function(D) {
  DWI<-readNIfTI(D,reorient = F)
  b1000<-dwi #dim (b1000) [1] 384 384  32   2
  k<-dwi@.Data
  b1000k<-k[,,,2] #dim(b1000k) [1] 384 384  32
  writeNIfTI(b1000k,"b1000")
}
```

Measurement of volume requires information on the dimensions of voxel.

```{r 2-Data-Wrangling-27-3, warning=F}
#measure volume
A="./Ext-Data/3000F_mca_blur.nii"

VoxelDim<-function(A){
  library(oro.nifti)
  img<-readNIfTI(A,reorient = F)
  VoxDim<-pixdim(img)
Volume<-sum(img>.5)*VoxDim[2]*VoxDim[3]*VoxDim[4]/1000
Volume
}

VoxelDim(A)
```

Find unsigned angle between 2 vectors k and k1

```{r 2-Data-Wrangling-27-4, warning=F}

Morpho::angle.calc(k,k1)

```

Determine centre of gravity of an object.

```{r 2-Data-Wrangling-27-5, warning=F}
#centre of gravity
neurobase::cog(img)
```

### Combining arrays

This is an illustration of combining array using _cbind_.

```{r 2-Data-Wrangling-28}
#stack arrays
k2<-cbind(k,k1)
dim(k2) ### [1] 902629      2

```

The _abind_ function produces a different array output. Later we will repeat the same exercise using _list_ function.

```{r 2-Data-Wrangling-28-1}
#combine multi-dimensional arrays 
ab<-abind::abind(k,k1)
dim(ab) ### [1]  91 109 182
```

This example uses 25 files. Rather than open one file at a time create a list from pattern matching.

```{r 02-Data-Wrangling-28-2, warning=F}
library(oro.nifti)
library(abind)
library(CHNOSZ) # for working with arrays
library(RNiftyReg)

#create a list using pattern matching
mca.list<-list.files(path="./Ext-Data/",pattern = "*.nii", full.names = TRUE)

#length of list
length(mca.list)
#read multiple files using lapply function

#use lappy to read in the nifti files
#note lapply returns a list
mca.list.nii <- lapply(mca.list, readNIfTI)

class(mca.list.nii)
```

This example illustrates how to view the first image in the list.

```{r 02-Data-Wrangling-28-2-1, warning=F}
#view each image in the list
neurobase::ortho2(mca.list.nii[[1]])
```

In this example, the first 3 segmented images from the list are averaged and viewed.

```{r 02-Data-Wrangling-28-2-2, warning=F}
#view average image
mca_ave3<-(mca.list.nii[[5]]+mca.list.nii[[6]]+mca.list.nii[[7]])/3
neurobase::ortho2(mca_ave3)
```

The output below is the same as above but is performed on arrays. The _image_data_ function from _oro.nifti_ library extracts the image attribute from the slot .Data.

```{r 02-Data-Wrangling-28-2-3, warning=F}
#extract multiple arrays using lapply
mca.list.array<-lapply(mca.list.nii, img_data)

m3<-(mca.list.array[[5]]+mca.list.array[[6]]+mca.list.array[[7]])/3

#compare this with the output from above
neurobase::double_ortho(m3, mca_ave3)
```

Arrays can be extracted from list using _list2array_ function.

```{r 02-Data-Wrangling-28-2-4, warning=F}
class(mca.list.array)

#convert list to array
#CHNOSZ function
m.listarray<-CHNOSZ::list2array(mca.list.array)#91 109  91  25

class(m.listarray)
```

### Math operation on multidimensional array

Before illustrating more complex operations on ultidimensional array or tensor, let's consider the basics of multidimensional array. The rank of a tensor represents the dimension of an array. Rank 0 represents 1 dimension and so on. 

```{r 02-Data-Wrangling-28-3, warning=F}

```

Here we use _apply_ function to average over every element of the multidimensional array. The first argument of _apply_ is the array, the second argument is the margin or the component for analysis and the last argument is the function. If the idea is to analyse the row then the margin argument is _c(1)_, column then the margin argumen is _c(2)_ and so on.

```{r 02-Data-Wrangling-28-3-1, warning=F}
ma<-apply(m.listarray,c(1,2,3), mean)
neurobase::ortho2(ma)


```

Thresholding can be performed using _mask_img_ function. This function can also be used to create a mask.

```{r 02-Data-Wrangling-28-3-2, warning=F}

ma_mask=neurobase::mask_img(ma, ma>0.1)

neurobase::double_ortho(ma_mask, ma)

```


### Math operation on list

In this example we us _lapply_ to a function within a list. This is an example of a functional or a function which takes a function as an input and return a vector as an output. In this example, a functional operates on one element of the list at a time. This example of functional is the same as the function _VoxelDim_ describes above.

```{r 02-Data-Wrangling-28-4, warning=F}

vox=unlist(lapply(mca.list.nii, 
           function(A) sum(A>.5)*
             #obtain voxel dimensions
             oro.nifti::pixdim(A)[2]*
             oro.nifti::pixdim(A)[3]*
             oro.nifti::pixdim(A)[4]/1000
           ))

vox




```



### Vectorising nifti object

One way of handling imaging data for analysis is to flatten the image, then create an empty array of the same size to return the image.

```{r 02-Data-Wrangling-28-5, warning=F}
#flatten 3D
niivector = as.vector(img[,,]) #902629

#Create empty array of same size to fill up
niinew = array(0, dim=dim(img))

#return to 3D
niinew = array(niivector, dim=dim(img))

#confirm
neurobase::ortho2(niinew)
```

Another way of creating vector from the image is to use _c_ function.

```{r 02-Data-Wrangling-28-5-1, warning=F}
#vector can also be created using c
niivector2 = c(img[,,]) #902629

```

### tar file

Image files can be large and are often stored as tar files. The _tar_ 
(tgz file), _untar_, _zip_ (gz file) and _unzip_ function are from the _utils_ library. 

```{r 02-Data-Wrangling-28-6, warning=F}
colin_1mm<-untar("./Data-Use/colin_1mm.tgz")
colinIm<-readNIfTI("colin_1mm") #1 x 1 x 1
class(colinIm)
neurobase::ortho2(colinIm)
```

The _readNIfTI_ call can open gz file without the need to call _unzip_ function.

```{r 02-Data-Wrangling-28-6-1, warning=F}
library(RNiftyReg)
epi_t2<- readNIfTI(system.file("extdata", "epi_t2.nii.gz", package="RNiftyReg"))
class(epi_t2)
neurobase::ortho2(epi_t2)

```


### Image registration

There are many different libraries for performing registration.

```{r 02-Data-Wrangling-29, warning=F}
library(RNiftyReg)

#example from data
source<-readNifti("./Data-Use/mca10_pca10_border10.nii.gz")
pixdim(source)

colin_1mm<-untar("./Data-Use/colin_1mm.tgz")
target<-readNifti("colin_1mm")
pixdim(target)
target
#register source to target 
result <- niftyreg(source, target)
#affine transformation
result$forwardTransforms
#image in target space
result$image
neurobase::ortho2(result$image)

```

Output from _RNiftyReg_ are _niftiImage_ objects. They can be converted to _oro.nifti_ objects using _nii2oro_ function.

```{r 02-Data-Wrangling-29-1, warning=F}

otarget<-nii2oro(target)
oimage<-nii2oro(result$image)

overlay(otarget, y=oimage,z = 90, plot.type = "single" )
```

### Rescaling

Perform affine registration and resampling of image using the transformation file.

```{r 02-Data-Wrangling-30, warning=F}
#affine
ica1000<-readNifti("./Ext-Data/1000M_ica.nii")
ica1000

colin_affine<-buildAffine(source=ica1000, target=target)
#apply transformation from above
#assume 1000M_ica.nii and source are in the same space
colin_like<-applyTransform(colin_affine,ica1000)
neurobase::ortho2(colin_like)

```

Resampling an image to different dimensions. This example is different from above in which rescaling is performed as part of registration to higher resolution image. Here the _rescale_ function from _RNiftyReg_ library is used to change the dimensions from 1x1x1 mm to 2x2x2 mm.

```{r 02-Data-Wrangling-30-1, warning=F}

ica1000.rescale<-RNiftyReg::rescale(ica1000,c(.5,.5,.5))

ica1000

#compare with rescale

ica1000.rescale

```

### MNI template 

There are several different MRI templates. The well known one is the MNI 152 template [@pmid11545704]. This was developed from male right-handed medical students. The MNI 152 is also known as International Consortium for Brain Mapping (ICBM) 152.

### Atlases

A list of available atlases for human and animals is available at https://loni.usc.edu/research/atlases. 

#### AAL atlas

The automated anatomical labeling (AAL) atlas of activation contains 45 volume of interest in each hemisphere [@pmid11771995]. The atlas is aligned to MNI 152 coordinates. The updated AAL has additional parcellation of orbitofrontal cortex. AAL3 update includes further parcellation of thalamus.

```{r 02-Data-Wrangling-31, warning=F}
library(rgl)
library(misc3d)
library(MNITemplate)
#source("https://neuroconductor.org/neurocLite.R")
#neuro_install('aal')
library(aal)
library(neurobase)
library(magick)
library(oro.nifti)

img = aal_image()
template = readMNI(res = "2mm")
cut <- 4500
dtemp <- dim(template)

# All of the sections you can label
labs = aal_get_labels()

# highlight - in this case the Cingulate_Post_L
cingulate = labs$index[grep("Cingulate_Post_R", labs$name)]

#mask of object for rendering
mask = remake_img(vec = img %in% cingulate, img = img)

#contour for MNI template
contour3d(template, x=1:dtemp[1], y=1:dtemp[2], z=1:dtemp[3], level = cut, alpha = 0.1, draw = TRUE)

#contour for mask
contour3d(mask, level = c(0.5), alpha = c(0.5), add = TRUE, color=c("red") )

### add text
text3d(x=dtemp[1]/2, y=dtemp[2]/2, z = dtemp[3]*0.98, text="Top")
text3d(x=-0.98, y=dtemp[2]/2, z = dtemp[3]/2, text="Right")

#create movie
#movie file is saved to temporary folder
#movie3d(spin3d(),duration=30)

#add digital map of mca territory
MCA<-readNIfTI("./Data-Use/MCA_average28_MAP_100.nii")

#mask2 = remake_img(vec = img %in% source, img = img)
contour3d(template, x=1:dtemp[1], y=1:dtemp[2], z=1:dtemp[3], level = cut, alpha = 0.1, draw = TRUE)

#contour for mask
contour3d(MCA, level = c(0.5), alpha = c(0.5), add = TRUE, color=c("Yellow"))
#add frontal
angular = labs$index[grep("Angular_R", labs$name)]
#mask of object for rendering
mask2 = remake_img(vec = img %in% angular, img = img)
contour3d(mask2, level = c(0.5), alpha = c(0.5), add = TRUE, color=c("red"))
#add cingulate
contour3d(mask, level = c(0.5), alpha = c(0.5), add = TRUE, color=c("blue"))
### add text
text3d(x=dtemp[1]/2, y=dtemp[2]/2, z = dtemp[3]*0.98, text="Top")
text3d(x=-0.98, y=dtemp[2]/2, z = dtemp[3]/2, text="Right")

#create movie
#movie file is saved to temporary folder
#movie3d(spin3d(),duration=5)
#rglwidget()

```

#### Eve template

The Eve template is from John Hopkins [@pmid19385016]. It is a single subject high resolution white matter atlas that has been morphed into MNI 152 coordinates. The atlas is parcellated into 176 regions based on ICBM-DTI-81 atlas.

```{r 02-Data-Wrangling-32, warning=F}
#source("https://neuroconductor.org/neurocLite.R")
#neuro_install('EveTemplate', release = "stable", release_repo = "github")

library(EveTemplate)

eve_labels = readEveMap(type = "II")
eve_labels
neurobase::ortho2(eve_labels)
```

```{r 02-Data-Wrangling-32-1, warning=F}
library(RColorBrewer)
library(tidyverse)
unique_labs = eve_labels %>% 
  c %>% 
  unique %>% 
  sort 
breaks = unique_labs
rf <- colorRampPalette(rev(brewer.pal(11,'Spectral')))
cols <- rf(length(unique_labs))

neurobase::ortho2(eve_labels, col = cols, breaks = c(-1, breaks))
```

#### Sensorimotor tract atlas

Template for corticofugal tracts from primary motor cortex, dorsal premotor cortex, ventral premotor cortex, supplementary motor area (SMA), pre-supplementary motor area (preSMA), and primary somatosensory cortex is available from [@pmid28334314]. Below is an illustration of the M1 tract obtained from LRNLAB.

```{r 02-Data-Wrangling-33, warning=F}

RightM1<-readNifti("./Ext-Data/Right-M1-S-MATT.nii")

neurobase::ortho2(RightM1)

#to down weight the voxel from 1 mm to 2 mm
RightM1.rescale<-RNiftyReg::rescale(RightM1,c(.5,.5,.5))

RightM1o<-nii2oro(RightM1)

#dimensions of RightM1o (182 218 182) and eve_labels (181 217 181) are dissimilar
#overlay(eve_labels, y=RightM1o, z=90,plot.type="single")
```

## ECG Signal processing

The ECG records the electrical signal from the heart. In a clinical record it is performed as a 12 lead recording. The ECG contains an initial P wave which originates from the atrium. The P wave is absent in patients with atrial fibrillation. The RR interval is used to measure the heart rate. A false assumption is that the heart rate is constant but measurement shows beat to beat variation. Heart rate variability is a feature of health.

#### ECG data

The ecg dataset of one patient contains 2048 observations collected at a rate of 180 samples per second. 

```{r 02-Data-Wrangling-35, warning=F}
library(ade4)
data("ecg") #ts object
#Time Series:
#Start = 0.31 
#End = 11.6822222222222 
#Frequency = 180
head(ecg)
```

```{r 02-Data-Wrangling-35-1, warning=F}
plot(ecg)
```

Let's look now at the Hart dataset.

```{r 02-Data-Wrangling-35-2, warning=F}

ECG<-read.csv("../../DataMining/python_journey/Heart/ECG/data.csv")

#ECG is a dataframe object

plot(as.ts(ECG)) # from base R

```

create a ts object by providing starting and end time and frequency. the plot of the data now has a new x limit.

```{r 02-Data-Wrangling-35-3, warning=F}

ECG1<-ts(ECG$hart, start=c(0.31,13.7), frequency=180)

plot(ECG1)
```



```{r 02-Data-Wrangling-35-4, warning=F}
EEGECG<-read.csv("../../DataMining/python_journey/Heart/ECG/eeg_stroke_ecg.csv")

#this data has 2 columns time and ECG

plot(as.ts(EEGECG$ECG))

ECG2<-ts(EEGECG$ECG, start=c(0.31,6.75), frequency=60)
plot(ECG2)

```


Here we illustrate the use of _RHRV_ package to analyse ECG signal [@doi10.1007/978-3-319-65355-6]. The code is provided on the RHRV website https://rhrv.r-forge.r-project.org/documentation.html. The example.beats data was download from this website and stored in the Data-Use folder. Here we make changes regarding the path of the data. 

```{r 02-Data-Wrangling-35-5, warning=F}
library(RHRV)

hrv.data = CreateHRVData()
hrv.data = SetVerbose(hrv.data, TRUE)

#setwd("C:/RHRV")
hrv.data = LoadBeatAscii(hrv.data, "example.beats.txt", 
                         RecordPath = "./Data-Use/" )

plot(hrv.data$Beat$Time)

hrv.data = BuildNIHR(hrv.data)
PlotNIHR(hrv.data)

hrv.data = FilterNIHR(hrv.data)
PlotNIHR(hrv.data)


```

## EEG signal processing

The _eegUtils_ package has useful methods for plotting EEG. https://craddm.github.io/eegUtils/index.html. According to the site, it has functions for importing data from Biosemi, Brain Vision Analyzer, and EEGLAB.

```{r 02-Data-Wrangling-36, warning=F}

#devtools::install_github("mne-tools/mne-r")
#remotes::install_github("craddm/eegUtils@develop")
library(eegUtils)
plot_butterfly(demo_epochs)
```


```{r 02-Data-Wrangling-36-1, warning=F}
topoplot(demo_epochs, 
         time_lim = c(.22, .25 ))
```

The following data is from https://datashare.ed.ac.uk/handle/10283/2189

```{r 02-Data-Wrangling-36-2, warning=F, eval=F}
library(eegUtils)
library(R.matlab)
limo_test <- import_set("limo_dataset_S1.set")
limo_cont <- R.matlab::readMat("continuous_variable.mat")
limo_cat <- readr::read_csv("categorical_variable.txt",
                            col_names = c("cond_lab"))
```

The _MNE-R_ package is an interface to _MNE_ package in Python.

## Python 

Python can be run directly from R markdown file. It requires that python be specified instead of R. The use of python here requires that Miniconda or Anaconda be installed. Installation of [Miniconda][Minconda environment] via _reticulate_ package will be shown below.

```{python 02-Data-Wrangling-37, warning=F}
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

#dataset containing locations of ms clinics in Victoria
dataset = pd.read_csv('./Data-Use/msclinic.csv') #Read data from CSV datafile
dat=pd.DataFrame(dataset)
#print 10 rows
print(dat.head(10))
exit
```

Passing Python object to R and _py$_ in front of Python object in R.

```{r 02-Data-Wrangling-37-1, warning=F, eval=F}

head(py$dat)

```
To pass a R object to python then add _r._ in front of object. 

```{python 02-Data-Wrangling-37-2, warning=F}

#The ECG data is now passed as r.ECG
print(r.ECG)
```

The data can now be plotted using _matplotlib_ library from Python.

```{python 02-Data-Wrangling-37-3, warning=F, eval=F}
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import math

#Matplotlib
plt.title("Heart Rate Signal") #The title of our plot

#ECG is data frame and hart is the column
plt.plot(r.ECG.hart) #Draw the plot object

#Display the plot
plt.show() 
exit
```

### Reticulate

Information on the use of Python in R is available at https://rstudio.github.io/reticulate/. The package _reticulate_ can import Python function to work directly in R. Note that the chunk code heading here is r.

```{r 02-Data-Wrangling-38, warning=F}
library(reticulate)
os <- import("os") #os is operating system package
os$listdir(".")
```

Here we provide another example on how to use Python in R. Note the change in the way we extract the _stats_ module from _scipy_ Python package.

```{r 02-Data-Wrangling-38-1, warning=F}
data("mtcars") #mtcars data in R

library(reticulate)
np<-import("numpy")
pd<-import("pandas")

#equivalent in Python is from scipy import stats
sc<-import("scipy")
sc$stats$linregress(mtcars$mpg,mtcars$cyl)

```

### Minconda 

Miniconda and Anaconda  can be installed directly from its website. Here we will illustrate installation of Miniconda from Rstudio. The _install_miniconda_ function from _reticulate_ library download Miniconda from the web. 

```{r 02-Data-Wrangling-39, warning=F}
#library(reticulate)

#this function is turned off as it only needs to be done once
#install_miniconda(path = miniconda_path(), update = TRUE, force = FALSE)

```

To find the libraries install in Miniconda

```{r 02-Data-Wrangling-39-1, warning=F, eval=F}

conda list

```

### Python environment

Unless specified, the default environment is r-reticulate. Setting the Python environment is important to avoid package incompatibility. To set the environment

```{r 02-Data-Wrangling-40, warning=F}

library(reticulate)
#virtualenv_create("SignalProcessing")


```

Some Python libraries such as _pycox_ can be installed in R using install_py... this way.Some python packages have 

```{r 02-Data-Wrangling-40-1, warning=F}
library(reticulate)
#library(survivalmodels)
#install pycox for survivalmodels
#install_pycox(pip = TRUE, install_torch = TRUE)
#install_keras(pip = TRUE, install_tensorflow = TRUE)

#install other Python packages
#this is similar to pip install torch
#install_torch(method = "auto", conda = "auto", pip = TRUE)

```

## Matlab

The package _R.mat_ provides interface between R and Matlab. This is useful for running EEG analysis where we import analysis from Matlab for visualisation in R. Matlab must be installed to for this to run.

## Stata

The package _Rs\Stata_ provides interface between R and Stata. Stata must be installed to for this to run.

Reference a figure by its code chunk label with the `fig:` prefix, e.g., see Figure \@ref(fig:nice-fig). Similarly, you can reference tables generated from `knitr::kable()`, e.g., see Table \@ref(tab:nice-tab).

```{r nice-tab, tidy=FALSE}
knitr::kable(
  df, caption = 'Table containing uncleaned data above',
  booktabs = TRUE
)
```

```{r nice-tab2, tidy=FALSE}
knitr::kable(
  Table2, caption = 'Table containing cleaned data above',
  booktabs = TRUE
)
```